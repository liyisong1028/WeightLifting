dir()
setwd(dir()[1])
shiny::runApp()
shiny::runApp()
shiny::runApp()
shiny::runApp()
runApp("Example 1")
dir()
getwd()
setwd("D:/Baidu Cloud/Crosby MBA Program 2015 Spring/RDIR/")
runApp("Example 1")
shiny::runApp('Example 1')
?runExample
shiny::runApp('Example 1')
install.library("manipulate")
install.libraries("manipulate")
installs("manipulate")
install.packages("manipulate")
library(manipulate)
?manipulate
getwd()
install.packages("rCharts")
dTable(airquality, sPaginationType = "full_numbers")
d <- data.frame(airquality, stringsAsFactors = FALSE) print(d)
d <- data.frame(airquality, stringsAsFactors = FALSE)
print(d)
shiny::runApp('Example 2')
install.packages("UsingR")
shiny::runApp('Example 2')
shiny::runApp('Example 2')
shiny::runApp('Example 2')
runApp("Example 1")
?rCharts
airquality
require(devtools)
install_github('rCharts', 'ramnathv')
dTable(airquality, sPaginationType = "full_numbers")
dTable?
?
??
()
require(rCharts)
dt <- dTable(
iris,
sPaginationType=  "full_numbers";
)
dt <- dTable(airquality, sPaginationType = "full_numbers")
dt
?caret
install.packages("caret")
?kernlab
install.packages("kernlab")
install.packages("ISLR")
install.packages("ISLR")
install.packages("ISLR")
install.packages("ISLR")
library(AppliedPredictiveModeling)
library(caret)
data(AlzheimerDisease)
install.packages("AppliedPredictiveModeling")
diagnois
diagnosis
adData = data.frame(diagnosis,predictors)
testIndex = createDataPartition(diagnosis, p = 0.50,list=FALSE)
training = adData[-testIndex,]
testing = adData[testIndex,]
library(AppliedPredictiveModeling)
library(caret)
data(AlzheimerDisease)
adData = data.frame(diagnosis,predictors)
testIndex = createDataPartition(diagnosis, p = 0.50,list=FALSE)
training = adData[-testIndex,]
testing = adData[testIndex,]
adData = data.frame(predictors)
trainIndex = createDataPartition(diagnosis,p=0.5,list=FALSE)
training = adData[trainIndex,]
testing = adData[-trainIndex,]
View(training)
adData = data.frame(diagnosis,predictors)
testIndex = createDataPartition(diagnosis, p = 0.50,list=FALSE)
training = adData[-testIndex,]
testing = adData[testIndex,]
View(testing)
library(AppliedPredictiveModeling)
data(concrete)
library(caret)
set.seed(975)
inTrain = createDataPartition(mixtures$CompressiveStrength, p = 3/4)[[1]]
training = mixtures[ inTrain,]
testing = mixtures[-inTrain,]
View(training)
install.packages("Hmisc")
rownames
flyash <- cut2(training$FlyAsh, g=3)
library(Hmisc)
flyash <- cut2(training$FlyAsh, g=3)
qplot(training$CompressiveStrength, rownames(training), colour = flyash)
qplot(training$CompressiveStrength, rownames(training), colour = flyash)
qplot(as.numeric(rownames(training)),training$CompressiveStrength, colour = flyash)
age <- cut2(training$Age, g=5)
qplot(as.numeric(rownames(training)),training$CompressiveStrength, colour = age)
age <- cut2(training$Age, g=3)
qplot(as.numeric(rownames(training)),training$CompressiveStrength, colour = age)
age <- cut2(training$Age, g=3)
qplot(as.numeric(rownames(training)),training$CompressiveStrength, colour = age)
age <- cut2(training$Age, g=4)
qplot(as.numeric(rownames(training)),training$CompressiveStrength, colour = age)
qplot(training$age,training$CompressiveStrength)
qplot(training$age, training$CompressiveStrength)
qplot(training$Age, training$CompressiveStrength)
qplot(as.numeric(rownames(training)),training$CompressiveStrength, colour = age)
library(AppliedPredictiveModeling)
data(concrete)
library(caret)
set.seed(975)
inTrain = createDataPartition(mixtures$CompressiveStrength, p = 3/4)[[1]]
training = mixtures[ inTrain,]
testing = mixtures[-inTrain,]
hist(training$SuperPlasticizer )
hist(training$SuperPlasticizer)
hist(as.numeric(training$SuperPlasticizer))
hist(as.numeric(training$SuperPlasticizer), breaks = 5)
hist(as.numeric(training$SuperPlasticizer), breaks = 20)
hist(training$SuperPlasticizer, breaks = 20)
?hist
View(training)
str(training)
hist(training$SuperPlasticizer, breaks = 20)
hist(training$SuperPlasticizer, breaks = 30)
hist(training$Superplasticizer, breaks = 30)
hist(log(training$Superplasticizer + 1), breaks = 30)
hist(training$Superplasticizer, breaks = 30)
hist(log(training$Superplasticizer + 1), breaks = 30)
hist(log(training$Superplasticizer), breaks = 30)
hist(log(training$Superplasticizer + 1), breaks = 30)
library(caret)
library(AppliedPredictiveModeling)
set.seed(3433)
data(AlzheimerDisease)
adData = data.frame(diagnosis,predictors)
inTrain = createDataPartition(adData$diagnosis, p = 3/4)[[1]]
training = adData[ inTrain,]
testing = adData[-inTrain,]
View(training)
names(training)
predictor<-training[,58:69]
View(predictors)
View(predictor)
preproc <- preProcess(predictor, method = "pca")
summary(preproc)
preproc
?preProcess
preproc <- preProcess(predictor, method = "pca", thresh = 0.95)
preproc
preproc <- preProcess(predictor, method = "pca", thresh = 0.9)
preproc
library(caret)
library(AppliedPredictiveModeling)
set.seed(3433)
data(AlzheimerDisease)
adData = data.frame(diagnosis,predictors)
inTrain = createDataPartition(adData$diagnosis, p = 3/4)[[1]]
training = adData[ inTrain,]
testing = adData[-inTrain,]
View(predictor)
fit1<-train(diagnosis~IL_11+IL_13+IL_16+IL_17E+IL_1alpha+IL_3+IL_4+IL_5+IL_6_Receptor+IL_7+IL_8, method="glm", data = training)
fit1<-train(diagnosis~ IL_11 + IL_13 + IL_16 + IL_17E + IL_1alpha + IL_3 + IL_4 + IL_5 + IL_6_Receptor + IL_7 + IL_8, method="glm", data = training)
install.packages("e1071")
fit1<-train(diagnosis~ IL_11 + IL_13 + IL_16 + IL_17E + IL_1alpha + IL_3 + IL_4 + IL_5 + IL_6_Receptor + IL_7 + IL_8, method="glm", data = training)
confusionMatrix(testing$diagnosis,predict(fit1,testing))
fit2<-train(diagnosis~ IL_11 + IL_13 + IL_16 + IL_17E + IL_1alpha + IL_3 + IL_4 + IL_5 + IL_6_Receptor + IL_7 + IL_8, method="glm", preProcess="pca", data = training)
fit2<-train(diagnosis~ IL_11 + IL_13 + IL_16 + IL_17E + IL_1alpha + IL_3 + IL_4 + IL_5 + IL_6_Receptor + IL_7 + IL_8, method="glm", preProcess="pca", thresh = 0.8, threstdata = training)
View(training)
fit2<-train(diagnosis~ IL_11 + IL_13 + IL_16 + IL_17E + IL_1alpha + IL_3 + IL_4 + IL_5 + IL_6_Receptor + IL_7 + IL_8, method="glm", preProcess="pca", thresh = 0.8, data = training)
?train
fit2<-train(diagnosis~ IL_11 + IL_13 + IL_16 + IL_17E + IL_1alpha + IL_3 + IL_4 + IL_5 + IL_6_Receptor + IL_7 + IL_8, method="glm", preProcess="pca", data = training)
fit2<-train(diagnosis~ IL_11 + IL_13 + IL_16 + IL_17E + IL_1alpha + IL_3 + IL_4 + IL_5 + IL_6_Receptor + IL_7 + IL_8, method="glm", preProcess="pca", thresh = 0.8, data = training)
?train
fit2<-train(diagnosis~ IL_11 + IL_13 + IL_16 + IL_17E + IL_1alpha + IL_3 + IL_4 + IL_5 + IL_6_Receptor + IL_7 + IL_8, method="glm", preProcess="pca", preProcOptions = list(thresh = 0.8, ICAcomp = 3, k = 5), data = training)
ctrl<-trainControl(preProcOptions = list(thresh = 0.8, ICAcomp = 3, k = 5))
fit2<-train(diagnosis~ IL_11 + IL_13 + IL_16 + IL_17E + IL_1alpha + IL_3 + IL_4 + IL_5 + IL_6_Receptor + IL_7 + IL_8, method="glm", preProcess="pca", trControl = ctrl, data = training)
confusionMatrix(testing$diagnosis,predict(fit2,testing))
confusionMatrix(testing$diagnosis,predict(fit1,testing))
summary(fit1)
summary(fit2)
library(caret)
library(AppliedPredictiveModeling)
set.seed(3433)
data(AlzheimerDisease)
adData = data.frame(diagnosis,predictors)
inTrain = createDataPartition(adData$diagnosis, p = 3/4)[[1]]
training = adData[ inTrain,]
testing = adData[-inTrain,]
training = training[,c(1, 58:69)]
View(training)
testing = testing[,c(1, 58:69)]
fit1<-train(diagnosis ~., method="glm", data = training)
confusionMatrix(testing$diagnosis,predict(fit1,testing))
confusionMatrix(testing$diagnosis,predict(fit2,testing))
library(devtools)
install_github('slidify','ramnathv')
install_github('slidifyLibraries','ramnathv/slidify')
install_github('slidifyLibraries','ramnathv')
library(AppliedPredictiveModeling)
data(segmentationOriginal)
library(caret)
data <- segmentationOriginal
View(data)
training <- data[data$Case == "Train",]
testing <- data[data$Case == "Test",]
set.seed(125)
fit <- train(Class ~., method = "rpart", data = training)
print(fit$finalModel)
library(pgmm)
data(olive)
olive = olive[,-1]
install.packages("pgmm")
library(pgmm)
data(olive)
olive = olive[,-1]
View(olive)
fit1 <- train(Area ~., method="rpart",data = olive)
fit1 <- train(Area ~., method="rpart",data = olive)
fit1$finalModel
predict(fit1, newdata = as.data.frame(t(colMeans(olive))))
library(ElemStatLearn)
data(SAheart)
set.seed(8484)
train = sample(1:dim(SAheart)[1],size=dim(SAheart)[1]/2,replace=F)
trainSA = SAheart[train,]
testSA = SAheart[-train,]
install.packages("ElemStatLearn")
library(ElemStatLearn)
data(SAheart)
set.seed(8484)
train = sample(1:dim(SAheart)[1],size=dim(SAheart)[1]/2,replace=F)
trainSA = SAheart[train,]
testSA = SAheart[-train,]
set.seed(13234)
View(trainSA)
?SAheart
fit<-train(chd ~ age + alcohol + obesity + tobacco + typea +ldl, method = "glm", family = "binomial", data = trainSA)
pred<-predict(fit, testSA)
missClass = function(values,prediction){sum(((prediction > 0.5)*1) != values)/length(values)}
missClass(testSA$chd, pred)
pred1<-predict(fit,trainSA)
missClass(trainSA$chd, pred1)
library(ElemStatLearn)
data(vowel.train)
data(vowel.test)
vowel.train
head(vowel.t)
head(vowel.test)
vowel.train$y<-as.factor(vowel.train$y)
vowel.test$y<-as.factor(vowel.test$y)
set.seed(33833)
fit<-train(y~.,data = vowel.train, method = "rf", proxy = T)
fit<-train(y~.,data = vowel.train, method = "rf", proxy = T)
?varlmp
varlmp
library(caret)
varlmp
fit
str(fit)
fit$importance
fit$finalModel
fit$finalModel$importance
varlmp(fit)
varImp(fit)
set.seed(33833)
fit<-train(y~.,data = vowel.train, method = "rf", proxy = T)
varImp(fit)
?VarImp
?varImp
varImp(fit)
?randomForest
fit <- randomForest(y~., data = vowel.train, importance = T)
order(fit$importance[,13],decreasing=T)
fit
fit$importance
varImp(fit)
?varImp
varImp.randomForest(fit)
filerVarImp
?filerVarImp
set.seed(33833)
fit<-train(y~.,data = vowel.train, method = "rf", proxy = T)
varImp(fit, useModel = "rf")
varImp(fit, useModel = T)
varImp(fit)
varImp(fit, useModel = F)
install.packages("pROC")
varImp(fit, useModel = F)
varImp(fit, useModel = T)
set.seed(33833)
fit<-train(y~.,data = vowel.train, method = "randomForest", proxy = T)
?train
install.packages("doMC")
install.packages("dplyr")
install.packages("stringr")
install.packages("vcd")
install.packages("randomForest")
install.packages("caret")
install.packages("shinny")
install.packages("shiny")
install.packages("R Markdown")
install.packages("xtable")
install.packages("maps")
install.packages("ggmap")
install.packages("parallel")
install.packages("XML")
install.packages("jsonlite")
install.packages("httr")
install.packages("xlsx")
install.packages("rmarkdown")
install.packages("ElemStatLearn")
install.packages("Formula")
install.packages("GGally")
install.packages("Hmisc")
install.packages("ISLR")
install.packages("kernlab")
install.packages("pgmm")
install.packages("pROC")
install.packages("rCharts")
install.packages("rpart")
install.packages("RSQLite")
install.packages("slidify")
require(devtools)
install_github("slidify", "ramnathv")
install_github("slidifyLibraries", "ramnathv")
demo()
getwd()
getwd()
?bar
?plot
if (!"caret" %in% (installed.packages())) {
install.packages("caret")
}
suppressMessages(library(caret))
if (!"randomForest" %in% (installed.packages())) {
install.packages("randomForest")
}
suppressMessages(library(randomForest))
if (!"doParallel" %in% (installed.packages())) {
install.packages("doParallel")
}
suppressMessages(library(doParallel))
training <- read.csv("./data/pml-training.csv", na.strings = c("NA", ""))
training$X <- NULL
testing <- read.csv("./data/pml-testing.csv", na.strings = c("NA", ""))
testing$X <- NULL
levels(testing$new_window) <- c("no","yes")
getwd()
setwd("D:/Baidu Cloud/Crosby MBA Program 2015 Spring/")
dir()
setwd(dir()[4])
dir()
setwd(dir()[8])
dir()
setwd(dir()[2])
dir()
training <- read.csv("./data/pml-training.csv", na.strings = c("NA", ""))
training$X <- NULL
testing <- read.csv("./data/pml-testing.csv", na.strings = c("NA", ""))
testing$X <- NULL
levels(testing$new_window) <- c("no","yes")
naPercent <- apply(training, 2, function(x) sum(is.na(x))/length(x))
filter <- naPercent < 0.95
wktrain <- training[,filter]
sum(napercent)
sum(naPercent)
sum(filer)
sum(filter)
barplot(sum(filter), cnum(training))
rnum
barplot(sum(filter), ncol(training))
barplot(c(sum(filter), ncol(training)))
x<-c(sum(filter), ncol(training))
x
colnames(x)
colnames(x)<-c("Filtered number of variables","Original number of variables")
names(x)<-c("Filtered number of variables","Original number of variables")
x
barplot(x
)
barplot(x)
names(x)<-c("Kept","Original")
barplot(x)
x <- c(ncol(training), sum(filter))
names(x)<-c("Original", "Kept")
barplot(x, main = "The Number of Variables comparison", ylab = "Number of Variables")
?barplot
cl <- makeCluster(detectCores())
registerDoParallel(cl)
wktrain <- wktrain[,5:59]
set.seed(525123)
modFit <- train(classe ~., data=wktrain, method="rf", ntree=10, proxy=T)
modFit
modFit$finalModel
head(getTree(modFit$finalModel,k=2))
varImp(modFit)
wlc <- classCenter(wktrain[, c("num_window", "roll_belt")], wktrain$classe, modFit$finalModel$prox)
modFit$finalModel$prox
qplot(num_window, roll_belt, col = classe, data = wktrain)
trainpred <- predict(modFit, wftrain)
wktrain$predRight <- pred == wktrain$classe
qplot(num_window, roll_belt, col = predRight, data = wktrain)
trainpred <- predict(modFit, wktrain)
wktrain$predRight <- pred == wktrain$classe
qplot(num_window, roll_belt, col = predRight, data = wktrain)
wktrain$predRight <- trainpred == wktrain$classe
qplot(num_window, roll_belt, col = predRight, data = wktrain)
table(trainpred, wktrain$classe)
qplot(num_window, roll_belt, col = classe, data = wktrain)
qplot(num_window, roll_belt, col = classe, data = wktrain, main = "Class by num_window and roll_belt")
