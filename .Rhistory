adData = data.frame(diagnosis,predictors)
testIndex = createDataPartition(diagnosis, p = 0.50,list=FALSE)
training = adData[-testIndex,]
testing = adData[testIndex,]
adData = data.frame(predictors)
trainIndex = createDataPartition(diagnosis,p=0.5,list=FALSE)
training = adData[trainIndex,]
testing = adData[-trainIndex,]
View(training)
adData = data.frame(diagnosis,predictors)
testIndex = createDataPartition(diagnosis, p = 0.50,list=FALSE)
training = adData[-testIndex,]
testing = adData[testIndex,]
View(testing)
library(AppliedPredictiveModeling)
data(concrete)
library(caret)
set.seed(975)
inTrain = createDataPartition(mixtures$CompressiveStrength, p = 3/4)[[1]]
training = mixtures[ inTrain,]
testing = mixtures[-inTrain,]
View(training)
install.packages("Hmisc")
rownames
flyash <- cut2(training$FlyAsh, g=3)
library(Hmisc)
flyash <- cut2(training$FlyAsh, g=3)
qplot(training$CompressiveStrength, rownames(training), colour = flyash)
qplot(training$CompressiveStrength, rownames(training), colour = flyash)
qplot(as.numeric(rownames(training)),training$CompressiveStrength, colour = flyash)
age <- cut2(training$Age, g=5)
qplot(as.numeric(rownames(training)),training$CompressiveStrength, colour = age)
age <- cut2(training$Age, g=3)
qplot(as.numeric(rownames(training)),training$CompressiveStrength, colour = age)
age <- cut2(training$Age, g=3)
qplot(as.numeric(rownames(training)),training$CompressiveStrength, colour = age)
age <- cut2(training$Age, g=4)
qplot(as.numeric(rownames(training)),training$CompressiveStrength, colour = age)
qplot(training$age,training$CompressiveStrength)
qplot(training$age, training$CompressiveStrength)
qplot(training$Age, training$CompressiveStrength)
qplot(as.numeric(rownames(training)),training$CompressiveStrength, colour = age)
library(AppliedPredictiveModeling)
data(concrete)
library(caret)
set.seed(975)
inTrain = createDataPartition(mixtures$CompressiveStrength, p = 3/4)[[1]]
training = mixtures[ inTrain,]
testing = mixtures[-inTrain,]
hist(training$SuperPlasticizer )
hist(training$SuperPlasticizer)
hist(as.numeric(training$SuperPlasticizer))
hist(as.numeric(training$SuperPlasticizer), breaks = 5)
hist(as.numeric(training$SuperPlasticizer), breaks = 20)
hist(training$SuperPlasticizer, breaks = 20)
?hist
View(training)
str(training)
hist(training$SuperPlasticizer, breaks = 20)
hist(training$SuperPlasticizer, breaks = 30)
hist(training$Superplasticizer, breaks = 30)
hist(log(training$Superplasticizer + 1), breaks = 30)
hist(training$Superplasticizer, breaks = 30)
hist(log(training$Superplasticizer + 1), breaks = 30)
hist(log(training$Superplasticizer), breaks = 30)
hist(log(training$Superplasticizer + 1), breaks = 30)
library(caret)
library(AppliedPredictiveModeling)
set.seed(3433)
data(AlzheimerDisease)
adData = data.frame(diagnosis,predictors)
inTrain = createDataPartition(adData$diagnosis, p = 3/4)[[1]]
training = adData[ inTrain,]
testing = adData[-inTrain,]
View(training)
names(training)
predictor<-training[,58:69]
View(predictors)
View(predictor)
preproc <- preProcess(predictor, method = "pca")
summary(preproc)
preproc
?preProcess
preproc <- preProcess(predictor, method = "pca", thresh = 0.95)
preproc
preproc <- preProcess(predictor, method = "pca", thresh = 0.9)
preproc
library(caret)
library(AppliedPredictiveModeling)
set.seed(3433)
data(AlzheimerDisease)
adData = data.frame(diagnosis,predictors)
inTrain = createDataPartition(adData$diagnosis, p = 3/4)[[1]]
training = adData[ inTrain,]
testing = adData[-inTrain,]
View(predictor)
fit1<-train(diagnosis~IL_11+IL_13+IL_16+IL_17E+IL_1alpha+IL_3+IL_4+IL_5+IL_6_Receptor+IL_7+IL_8, method="glm", data = training)
fit1<-train(diagnosis~ IL_11 + IL_13 + IL_16 + IL_17E + IL_1alpha + IL_3 + IL_4 + IL_5 + IL_6_Receptor + IL_7 + IL_8, method="glm", data = training)
install.packages("e1071")
fit1<-train(diagnosis~ IL_11 + IL_13 + IL_16 + IL_17E + IL_1alpha + IL_3 + IL_4 + IL_5 + IL_6_Receptor + IL_7 + IL_8, method="glm", data = training)
confusionMatrix(testing$diagnosis,predict(fit1,testing))
fit2<-train(diagnosis~ IL_11 + IL_13 + IL_16 + IL_17E + IL_1alpha + IL_3 + IL_4 + IL_5 + IL_6_Receptor + IL_7 + IL_8, method="glm", preProcess="pca", data = training)
fit2<-train(diagnosis~ IL_11 + IL_13 + IL_16 + IL_17E + IL_1alpha + IL_3 + IL_4 + IL_5 + IL_6_Receptor + IL_7 + IL_8, method="glm", preProcess="pca", thresh = 0.8, threstdata = training)
View(training)
fit2<-train(diagnosis~ IL_11 + IL_13 + IL_16 + IL_17E + IL_1alpha + IL_3 + IL_4 + IL_5 + IL_6_Receptor + IL_7 + IL_8, method="glm", preProcess="pca", thresh = 0.8, data = training)
?train
fit2<-train(diagnosis~ IL_11 + IL_13 + IL_16 + IL_17E + IL_1alpha + IL_3 + IL_4 + IL_5 + IL_6_Receptor + IL_7 + IL_8, method="glm", preProcess="pca", data = training)
fit2<-train(diagnosis~ IL_11 + IL_13 + IL_16 + IL_17E + IL_1alpha + IL_3 + IL_4 + IL_5 + IL_6_Receptor + IL_7 + IL_8, method="glm", preProcess="pca", thresh = 0.8, data = training)
?train
fit2<-train(diagnosis~ IL_11 + IL_13 + IL_16 + IL_17E + IL_1alpha + IL_3 + IL_4 + IL_5 + IL_6_Receptor + IL_7 + IL_8, method="glm", preProcess="pca", preProcOptions = list(thresh = 0.8, ICAcomp = 3, k = 5), data = training)
ctrl<-trainControl(preProcOptions = list(thresh = 0.8, ICAcomp = 3, k = 5))
fit2<-train(diagnosis~ IL_11 + IL_13 + IL_16 + IL_17E + IL_1alpha + IL_3 + IL_4 + IL_5 + IL_6_Receptor + IL_7 + IL_8, method="glm", preProcess="pca", trControl = ctrl, data = training)
confusionMatrix(testing$diagnosis,predict(fit2,testing))
confusionMatrix(testing$diagnosis,predict(fit1,testing))
summary(fit1)
summary(fit2)
library(caret)
library(AppliedPredictiveModeling)
set.seed(3433)
data(AlzheimerDisease)
adData = data.frame(diagnosis,predictors)
inTrain = createDataPartition(adData$diagnosis, p = 3/4)[[1]]
training = adData[ inTrain,]
testing = adData[-inTrain,]
training = training[,c(1, 58:69)]
View(training)
testing = testing[,c(1, 58:69)]
fit1<-train(diagnosis ~., method="glm", data = training)
confusionMatrix(testing$diagnosis,predict(fit1,testing))
confusionMatrix(testing$diagnosis,predict(fit2,testing))
library(devtools)
install_github('slidify','ramnathv')
install_github('slidifyLibraries','ramnathv/slidify')
install_github('slidifyLibraries','ramnathv')
library(AppliedPredictiveModeling)
data(segmentationOriginal)
library(caret)
data <- segmentationOriginal
View(data)
training <- data[data$Case == "Train",]
testing <- data[data$Case == "Test",]
set.seed(125)
fit <- train(Class ~., method = "rpart", data = training)
print(fit$finalModel)
library(pgmm)
data(olive)
olive = olive[,-1]
install.packages("pgmm")
library(pgmm)
data(olive)
olive = olive[,-1]
View(olive)
fit1 <- train(Area ~., method="rpart",data = olive)
fit1 <- train(Area ~., method="rpart",data = olive)
fit1$finalModel
predict(fit1, newdata = as.data.frame(t(colMeans(olive))))
library(ElemStatLearn)
data(SAheart)
set.seed(8484)
train = sample(1:dim(SAheart)[1],size=dim(SAheart)[1]/2,replace=F)
trainSA = SAheart[train,]
testSA = SAheart[-train,]
install.packages("ElemStatLearn")
library(ElemStatLearn)
data(SAheart)
set.seed(8484)
train = sample(1:dim(SAheart)[1],size=dim(SAheart)[1]/2,replace=F)
trainSA = SAheart[train,]
testSA = SAheart[-train,]
set.seed(13234)
View(trainSA)
?SAheart
fit<-train(chd ~ age + alcohol + obesity + tobacco + typea +ldl, method = "glm", family = "binomial", data = trainSA)
pred<-predict(fit, testSA)
missClass = function(values,prediction){sum(((prediction > 0.5)*1) != values)/length(values)}
missClass(testSA$chd, pred)
pred1<-predict(fit,trainSA)
missClass(trainSA$chd, pred1)
library(ElemStatLearn)
data(vowel.train)
data(vowel.test)
vowel.train
head(vowel.t)
head(vowel.test)
vowel.train$y<-as.factor(vowel.train$y)
vowel.test$y<-as.factor(vowel.test$y)
set.seed(33833)
fit<-train(y~.,data = vowel.train, method = "rf", proxy = T)
fit<-train(y~.,data = vowel.train, method = "rf", proxy = T)
?varlmp
varlmp
library(caret)
varlmp
fit
str(fit)
fit$importance
fit$finalModel
fit$finalModel$importance
varlmp(fit)
varImp(fit)
set.seed(33833)
fit<-train(y~.,data = vowel.train, method = "rf", proxy = T)
varImp(fit)
?VarImp
?varImp
varImp(fit)
?randomForest
fit <- randomForest(y~., data = vowel.train, importance = T)
order(fit$importance[,13],decreasing=T)
fit
fit$importance
varImp(fit)
?varImp
varImp.randomForest(fit)
filerVarImp
?filerVarImp
set.seed(33833)
fit<-train(y~.,data = vowel.train, method = "rf", proxy = T)
varImp(fit, useModel = "rf")
varImp(fit, useModel = T)
varImp(fit)
varImp(fit, useModel = F)
install.packages("pROC")
varImp(fit, useModel = F)
varImp(fit, useModel = T)
set.seed(33833)
fit<-train(y~.,data = vowel.train, method = "randomForest", proxy = T)
?train
install.packages("doMC")
install.packages("dplyr")
install.packages("stringr")
install.packages("vcd")
install.packages("randomForest")
install.packages("caret")
install.packages("shinny")
install.packages("shiny")
install.packages("R Markdown")
install.packages("xtable")
install.packages("maps")
install.packages("ggmap")
install.packages("parallel")
install.packages("XML")
install.packages("jsonlite")
install.packages("httr")
install.packages("xlsx")
install.packages("rmarkdown")
install.packages("ElemStatLearn")
install.packages("Formula")
install.packages("GGally")
install.packages("Hmisc")
install.packages("ISLR")
install.packages("kernlab")
install.packages("pgmm")
install.packages("pROC")
install.packages("rCharts")
install.packages("rpart")
install.packages("RSQLite")
install.packages("slidify")
require(devtools)
install_github("slidify", "ramnathv")
install_github("slidifyLibraries", "ramnathv")
demo()
getwd()
getwd()
getwd()
setwd("D:/Baidu Cloud/Crosby MBA Program 2015 Spring/")
list()
dir()
setwd(dir()[4])
dir()
setwd(dir()[8])
dir()
setwd(dir()[2])
dir()
data <- read.csv(".data/pml-training.csv")
data <- read.csv("./data/pml-training.csv")
View(data)
?read.csv
str(data)
?time
x1 <- as.time(data$raw_timestamp_part_1)
x1 <- time(data$raw_timestamp_part_1)
x1
?Time
table(data$class)
is.na(data$kurtosis_roll_belt)
sum(is.na(data$kurtosis_roll_belt))
str(data$kurtosis_roll_belt)
data <- read.csv("./data/pml-training.csv", na.strings = c("NA", ""))
View(data)
str(data)
data$X <- NULL
View(data)
library(caret)
?apply
apply(data,2, sum(is.na))
x<-apply(data,2, function(x) sum(is.na(x)))
?length
length(x)
length(data$skewness_yaw_belt)
y<-apply(data,2, function(x) sum(is.na(x))/length(x))
names(data)[y>80%]
names(data)
y>80%
y > 0.8
names(data)[y>0.9]
names(data)[y>0.95]
wkdata <- data[,naPercent > 0.95]
wkdata <- data[,y > 0.95]
View(wkdata)
wkdata <- data[,naPercent < 0.95]
wkdata <- data[,y < 0.95]
View(wkdata)
View(data)
data <- read.csv("./data/pml-training.csv", na.strings = c("NA", ""))
data$X <- NULL
naPercent <- apply(data,2, function(x) sum(is.na(x))/length(x))
wkdata <- data[,naPercent < 0.95]
summary(wkdata)
print
print(ncol(data), ncol(wkdata))
ncol
ncol(data)
c(ncol(data), ncol(wkdata))
library(xtable)
?xtable
xtable(c(ncol(data),ncol(wkdata)))
library(caret)
varnames <- names(data)[naPercent >= 0.95]
xtable(varnames)
varnames
supressMessages
supressMessage
SupressMessage
SupressMessages
Supress.Messages
names(wkdata)
modFit <- train(classe~., data = wkdata, method = "rf", proxy = T)
library(e1071)
install.packages(e1071)
install.packages("e1071")
modFit <- train(classe~., data = wkdata, method = "rf", proxy = T)
modFit <- randomForest(classe~.,data = wkdata)
modFIT
modFit
modFit$importance
modFit$importance[-order(modFit$importance)]
modFit$importance[order(modFit$importance)]
modFit$importance[order(-modFit$importance)]
names(modFit$importance)[order(-modFit$importance)]
rownames(modFit$importance)[order(-modFit$importance)]
wkdata <- wkdata[,5:]
wkdata <- wkdata[,5:59]
View(wkdata)
modFit <- randomForest(classe~.,data = wkdata)
modFit
modFit$finalModel
str(modFit)
testing <- read.csv("./data/pml-testing.csv", na.strings = c("NA", ""))
testing$X <- NULL
testing <- testing[,filter]
testing <- testing[,5:59]
naPercent <- apply(data, 2, function(x) sum(is.na(x))/length(x))
filter <- naPercent < 0.95
testing <- read.csv("./data/pml-testing.csv", na.strings = c("NA", ""))
testing$X <- NULL
testing <- testing[,filter]
testing <- testing[,5:59]
View(testing)
pred <- predict(modFit, testing)
View(testing)
training <- read.csv("./data/pml-training.csv", na.strings = c("NA", ""))
training$X <- NULL
testing <- read.csv("./data/pml-testing.csv", na.strings = c("NA", ""))
testing$X <- NULL
naPercent <- apply(training, 2, function(x) sum(is.na(x))/length(x))
filter <- naPercent < 0.95
wktrain <- training[,filter]
testing <- testing[,filter]
testing <- testing[,5:59]
wktrain <- wktrain[,5:59]
pred <- predict(modFit, testing)
View(testing)
pred <- predict(modFit, testing[,1:58])
testing <- testing[,1:58]
testing <- testing[,1:54]
pred <- predict(modFit, testing[,1:58])
pred <- predict(modFit, testing)
View(wktrain)
sum(names(testing)==names(wktrain[,1:54]))
str(testing)
str(wktrain)
?predict
modFit <- randomForest(classe~.,data = wktrain)
pred <- predict(modFit, testing)
levels(wktrain$new_window)
levels(testing$new_window)
levels(testing$new_window) <- c("no","yes")
levels(testing$new_window)
str(testing)
levels(wktrain$new_window)
str(wktrain$new_window)
pred <- predict(modFit, testing)
pred
getwd()
dir()
setwd("result")
dir()
pml_write_files = function(x){
n = length(x)
for(i in 1:n){
filename = paste0("problem_id_",i,".txt")
write.table(x[i],file=filename,quote=FALSE,row.names=FALSE,col.names=FALSE)
}
}
pml_write_files(pred)
modFit
str(modFit)
modFit$forest
str(modFit)
modFit$importance
pred <- predict(modFit, testing, proxy = T)
modFit <- randomForest(classe~.,data = wktrain, proxy = T)
str(modFit)
install.packages("raffle")
install.packages("rattle")
install.packages("shiny")
modFit<-train(classe ~., data = wktrain, method = "rf", proxy = T)
?rf
?randomforest
?randomForest
install.packages(doParallel)
install.packages("doParallel")
cl <- makeCluster(detectCores())
library(doParallel)
cl <- makeCluster(detectCores())
registerDoParallel(cl)
library(doParallel)
modFit<-train(classe ~., data = wktrain, method = "rf", ntree = 200, proxy = T)
modFit
pred<-predict(modFit$finalModel, testing)
View(wktrain)
testing$classe <- NA
pred<-predict(modFit$finalModel, testing)
testing$classe <- as.factor(rep(c("A","B","C","D","E"),4))
View(testing)
pred<-predict(modFit$finalModel, testing)
modFit$finalModel
str(modFit)
View(testing)
levels(testing$classe)
levels(wktrain$classe)
pred<-predict(modFit$finalModel, testing)
View(wktrain)
fit<-randomForest(classe~., data = wktrain)
fit
pred<-predict(fit1, testing)
pred<-predict(fit, testing)
pred
str(fit)
fit$terms
fancyRpartPlot(fit)
library(rattle)
fancyRpartPlot(fit)
fancyRpartPlot(modFit$finalModel)
modFit$finalModel
str(fit)
fancyRpartPlot(fit$forest)
fit$forest
str(fit)
fit
fiterr.rate
fit#err.rate
fit$err.rate
modFit$finalModel
str(modFit$finalModel)
pred<-predict(modFir, testing)
pred<-predict(modFit, testing)
pred
pred2<-predict(fit, testing)
pred1 == pred2
pred == pred2
fit1
fit
str(fit)
fit$err.rate$OOB
fit$importance
modFit$importance
str(modFit)
varImp(modFit)
getTree(modFit$finalModel,k=2)
fancyRpartPlot(getTree(modFit$finalModel,k=2))
fancyRpartPlot(modFit$finalModel)
wlc <- classCenter(wktrain[, c("num_window", roll_belt)], wktrain$classe, modFit$finalModel$prox)
wlc <- classCenter(wktrain[, c("num_window", "roll_belt")], wktrain$classe, modFit$finalModel$prox)
x<-wktrain[, c("num_window", "roll_belt")]
modFit$finalModel$prox
modFit$finalModel
modfit
modFit
View(training)
getwd()
setwd("D:/Baidu Cloud/Crosby MBA Program 2015 Spring/Coursera - Johns Hpkins - Data Science Specialization/08 - Practical Machine Learning/Projects")
download.file("https://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv", "./pml-testing.csv")
download.file("https://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv", "./data/pml-testing.csv")
modFit$finalModel
wlc <- classCenter(wktrain[, c("num_window", "roll_belt")], wktrain$classe, modFit$finalModel$prox)
wlc <- as.data.frame(wlc)
wlc$classe <- rownames(wlc)
p <- qplot(num_window, roll_belt, col = classe, data = wktrain)
p + geom_point(aes(x=num_window, y = roll_belt, col = classe, size = 5, shape = 4, data = wlc))
download.file("https://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv", "./data/pml-training.csv")
